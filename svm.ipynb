{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Support Vector Machines model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "<!-- <img src=\"img/svm/CV.png\" width=\"700\">\n",
    "<img src=\"img/svm/Cross-Val.png\" width=\"500\"> -->\n",
    "<table><tr><td><img src=\"img/svm/CV.png\" width=\"1000\"></td><td><img src=\"img/svm/Cross-Val.png\" width=\"1000\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "feature_columns = ['Pclass', 'Gender', 'Age', 'Fare', 'Family_count', 'Cabin_index']\n",
    "label_column = ['Survival']\n",
    "\n",
    "tr_features = pd.read_csv('dataset/train_dataset.csv', usecols=feature_columns)\n",
    "tr_labels = pd.read_csv('dataset/train_dataset.csv', usecols=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "<img src=\"img/svm/c.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "0.796 (+/-0.115) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.654 (+/-0.06) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.115) for {'C': 1, 'kernel': 'linear'}\n",
      "0.661 (+/-0.048) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.115) for {'C': 10, 'kernel': 'linear'}\n",
      "0.684 (+/-0.07) for {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "# kernels -> linear, radial basis function\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(svc, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/svm_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'models/svm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved model\n",
    "pipe = joblib.load('models/svm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Actual labels\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# test data to predict\n",
    "pr = pd.read_csv('dataset/test_dataset.csv')\n",
    "# remove the label column\n",
    "pred_cols = list(pr.columns.values)[:-1]\n",
    "# apply the whole pipeline to data\n",
    "pred = pd.Series(pipe.predict(pr[pred_cols]))\n",
    "\n",
    "# set of predictions\n",
    "print(\"Prediction\")\n",
    "print(pred[25:40].tolist())\n",
    "\n",
    "# select label column\n",
    "label_cols = list(pr.columns.values)[-1]\n",
    "\n",
    "# corresponding actual labels\n",
    "print(\"\\nActual labels\")\n",
    "print(pr[label_cols][20:35].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
