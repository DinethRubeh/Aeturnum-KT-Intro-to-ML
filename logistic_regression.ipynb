{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Fit and evaluate a model\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will fit and evaluate a simple Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "<!-- ![CV](img/lr/CV.png)\n",
    "![Cross-Val](img/lr/Cross-Val.png) -->\n",
    "<table><tr><td><img src=\"img/lr/CV.png\" width=\"1000\"></td><td><img src=\"img/lr/Cross-Val.png\" width=\"1000\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "feature_columns = ['Pclass', 'Gender', 'Age', 'Fare', 'Family_count', 'Cabin_index']\n",
    "label_column = ['Survival']\n",
    "\n",
    "tr_features = pd.read_csv('dataset/train_dataset.csv', usecols=feature_columns)\n",
    "tr_labels = pd.read_csv('dataset/train_dataset.csv', usecols=label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "<img src=\"img/lr/c.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 1}\n",
      "\n",
      "0.67 (+/-0.077) for {'C': 0.001}\n",
      "0.708 (+/-0.098) for {'C': 0.01}\n",
      "0.777 (+/-0.134) for {'C': 0.1}\n",
      "0.8 (+/-0.118) for {'C': 1}\n",
      "0.794 (+/-0.116) for {'C': 10}\n",
      "0.794 (+/-0.116) for {'C': 100}\n",
      "0.794 (+/-0.116) for {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000) # max_iter=1000\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Grid search with 5 fold cross validation\n",
    "cv = GridSearchCV(lr, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lr_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_, 'models/lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved model\n",
    "pipe = joblib.load('models/lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "[0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "Actual labels\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# test data to predict\n",
    "pr = pd.read_csv('dataset/test_dataset.csv')\n",
    "# remove the label column\n",
    "pred_cols = list(pr.columns.values)[:-1]\n",
    "# apply the whole pipeline to data\n",
    "pred = pd.Series(pipe.predict(pr[pred_cols]))\n",
    "\n",
    "# set of predictions\n",
    "print(\"Prediction\")\n",
    "print(pred[20:35].tolist())\n",
    "\n",
    "# select label column\n",
    "label_cols = list(pr.columns.values)[-1]\n",
    "\n",
    "# corresponding actual labels\n",
    "print(\"\\nActual labels\")\n",
    "print(pr[label_cols][20:35].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
